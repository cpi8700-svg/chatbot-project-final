import streamlit as st
import google.generativeai as genai
import os
import time

st.set_page_config(page_title="í˜„ì¥ ì§€ì› ì±—ë´‡", page_icon="ğŸ‘·")
st.title("ğŸ‘· í˜„ì¥ ì—…ë¬´/ì œí’ˆ ì§€ì›")

# API í‚¤ í™•ì¸
if "api_key" not in st.session_state or not st.session_state["api_key"]:
    st.error("ğŸš¨ ë©”ì¸ í™”ë©´(Main.py)ì—ì„œ API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”!")
    st.stop()

genai.configure(api_key=st.session_state["api_key"])

# --- PDF ìë™ ë¡œë”© (í´ë”ì— ìˆëŠ” íŒŒì¼ ì½ê¸°) ---
PDF_FILENAME = "manual.pdf"  # ë°°í¬í•  ë•Œ ì´ íŒŒì¼ì´ ê¼­ ê°™ì´ ì˜¬ë¼ê°€ì•¼ í•©ë‹ˆë‹¤!

if not os.path.exists(PDF_FILENAME):
    st.error(f"âš ï¸ '{PDF_FILENAME}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")
    st.stop()

# íŒŒì¼ ì—…ë¡œë“œ (ìºì‹±í•˜ì—¬ ë°˜ë³µ ì—…ë¡œë“œ ë°©ì§€)
if "worker_doc_cache" not in st.session_state:
    with st.spinner("ë§¤ë‰´ì–¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            uploaded_doc = genai.upload_file(path=PDF_FILENAME)
            
            # ì²˜ë¦¬ ëŒ€ê¸°
            while uploaded_doc.state.name == "PROCESSING":
                time.sleep(1)
                uploaded_doc = genai.get_file(uploaded_doc.name)
            
            st.session_state["worker_doc_cache"] = uploaded_doc
            st.toast("ë§¤ë‰´ì–¼ ë¡œë”© ì™„ë£Œ!", icon="âœ…")
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.stop()

# --- ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ---
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ì•ˆì „ ìˆ˜ì¹™ì´ë‚˜ ì œí’ˆì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”!"}]

for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("ì§ˆë¬¸ ì…ë ¥ (ì˜ˆ: ë¹„ìƒì‹œ ëŒ€ì²˜ ìš”ë ¹ì€?)"):
    st.chat_message("user").write(prompt)
    st.session_state["messages"].append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        msg_placeholder = st.empty()
        msg_placeholder.markdown("ğŸ” ë§¤ë‰´ì–¼ ê²€ìƒ‰ ì¤‘...")
        
        try:
            full_prompt = [
                "ë‹¹ì‹ ì€ í˜„ì¥ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.",
                "ì§ˆë¬¸:", prompt,
                "ì°¸ê³  ë¬¸ì„œ:", st.session_state["worker_doc_cache"]
            ]
            
            model = genai.GenerativeModel('gemini-3-flash-preview')
            response = model.generate_content(full_prompt)
            
            msg_placeholder.markdown(response.text)
            st.session_state["messages"].append({"role": "assistant", "content": response.text})
            
        except Exception as e:
            msg_placeholder.error("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")