import streamlit as st
import google.generativeai as genai

st.set_page_config(page_title="í˜„ì¥ ì—…ë¬´ ì§€ì›", page_icon="ğŸ‘·")
st.title("ğŸ‘· ë˜ë”•ìŠ¤ í˜„ì¥ ì‚¬ì›ìš© ì±—ë´‡")

# --- [1. API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°] ---
if "api_key" not in st.session_state or not st.session_state["api_key"]:
    if "GOOGLE_API_KEY" in st.secrets:
        st.session_state["api_key"] = st.secrets["GOOGLE_API_KEY"]
    else:
        st.warning("âš ï¸ ë©”ì¸ í˜ì´ì§€ì—ì„œ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()

# --- [2. AI ë¹„ì„œ ì„¤ì •] ---
try:
    genai.configure(api_key=st.session_state["api_key"])
except Exception as e:
    st.error(f"API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

# ëª¨ë¸ ì„¤ì • (ìµœì‹ ìƒ 2.0 ì‹œë„ -> ì•ˆë˜ë©´ 1.5 ìë™ ì „í™˜)
try:
    model = genai.GenerativeModel('gemini-3-flash-preview')
except:
    model = genai.GenerativeModel('gemini-3-flash-preview')

# --- [3. ì±„íŒ… í™”ë©´ ë§Œë“¤ê¸°] ---
st.info("ğŸ’¡ ë˜ë”•ìŠ¤ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”!")

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ì „ ëŒ€í™” ë‚´ìš© ë³´ì—¬ì£¼ê¸°
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì§ˆë¬¸ ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ì§ˆë¬¸ ì…ë ¥ (ì˜ˆ: ì‹œê¸‰ì€?)"):
    # 1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ í‘œì‹œ
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2. AIì˜ ë‹µë³€ ìƒì„±
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        try:
            # ğŸ”¥ [í•µì‹¬ ìˆ˜ì •] ì—…ë¡œë“œëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
            if "uploaded_files_cache" in st.session_state and st.session_state["uploaded_files_cache"]:
                # íŒŒì¼ì´ ìˆìœ¼ë©´: [ì§ˆë¬¸ + íŒŒì¼ë“¤]ì„ ë¬¶ì–´ì„œ ë³´ëƒ„ (ì´ê²Œ ë°”ë¡œ êµê³¼ì„œ í´ê³  ë‹µí•˜ê¸°!)
                content_to_send = [prompt] + st.session_state["uploaded_files_cache"]
                message_placeholder.markdown("ğŸ“˜ ë§¤ë‰´ì–¼ì„ ê²€í†  ì¤‘ì…ë‹ˆë‹¤...")
            else:
                # íŒŒì¼ì´ ì—†ìœ¼ë©´: ê·¸ëƒ¥ ì§ˆë¬¸ë§Œ ë³´ëƒ„ (ê²½ê³  ë©”ì‹œì§€ í¬í•¨)
                content_to_send = prompt
                st.caption("âš ï¸ í˜„ì¬ í•™ìŠµëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.")

            # AIì—ê²Œ ì§ˆë¬¸ ë˜ì§€ê¸°
            response = model.generate_content(content_to_send)
            full_response = response.text
            message_placeholder.markdown(full_response)
            
            # ë‹µë³€ ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            st.error("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë„ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.caption(f"ì—ëŸ¬ ë‚´ìš©: {e}")